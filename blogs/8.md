---
title: Algolia 使用
date: 2024/01/12
tags:
 - 博客
 - 搜索
categories:
 - 工具集
---
搭建的个人技术博客是基于vuepress的，内置的搜索只会提取文档的标题构建搜索索引，不能满足使用要求，需要实现全文搜索，因此，想借助第三方提供的免费搜索服务```Algolia DocSearch``` 来实现个人网站的全文搜索。

## 1. Algolia介绍

Algolia 是一个数据库实时搜索服务，能够提供毫秒级的数据库搜索服务，并且其服务能以 API 的形式方便地布局到网页、客户端、APP 等多种场景。

VuePress 的官方文档就是使用的 ```Algolia``` 搜索，使用 Algolia 搜索最大的好处就是方便，它会自动爬取网站的页面内容并构建索引，你只用申请一个 Algolia 服务，在网站上添加一些代码，就像添加统计代码一样，然后就可以实现一个 **<font style="color:red">全文搜索</font>** 功能。

### Algolia DocSearch

[Algolia DocSearch](https://www.algolia.com/developers/code-exchange/frontend-tools/docsearch/) 是 Algolia 提供的自动化的全文搜索服务，DocSearch 会定时爬取指定网站（通常就是我们的文档网站）上的内容，自动构建搜索索引，不需要繁琐的配置，操作简单，用户只需要用相关的 API 直接调用就行了。

### 基本原理

Algolia 服务器会 **定期抓取** 我们指定的 **文档地址** 中的内容进行分析并 **建立索引**，这样在网站搜索框中输入关键词后，前端会调用 ```Algolia DocSearch```的接口并显示搜索结果。这些请求、结果显示的相关逻辑都封装好了，我们要做的就是按要求插入代码、配置好网站样式以及搜索框。

### 使用要求

Algolia DocSearch 提供的免费服务是需要申请的，当我们的网站满足下列条件时，Algolia 那边的工作人员才会让我们的申请通过：

1. 我们必须是云文档网站的 所有者，网站必须是 **公开的**。

2. 网站内容必须是 **开源项目的技术文档** 或 **技术博客**。

3. 网站申请服务时必须有 **完整稳定的设计和内容**，即确认网站做好生产准备。

## 2. 申请Algolia DocSearch服务

前往 Algolia DocSearch Apply 网站，填写网站地址、邮箱、仓库地址等信息，然后提交申请。

![image-20240621110431204](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240621110431204.png)

提交申请后会给你的邮箱发送一个邮件让你耐心等待，一般不到一天就会再给你发送一个申请通过的邮件，其中附带有包含 **appId、apiKey、indexName和algolia**的账号创建链接，点击链接后设置密码后即可登录。

![image-20240622095810791](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240622095810791.png)

创建账号后，会自动登录，第一次登录时页面头部会显示邀请你加入应用，点击接受，如下：

![image-20240622100407769](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240622100407769.png)

## 3. 使用

### 登录爬虫后台

地址：[https://crawler.algolia.com/admin/](https://crawler.algolia.com/admin/)

![image-20240622100759966](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240622100759966.png)

可以看到右侧的records为0，说明爬虫有问题。

### 修改路径

点击左侧菜单中的"Editor"查看并编辑爬虫代码，注意看代码中的 pathsToMatch 路径，很明显是不对的，后面多了个 docs，将它改成正确的网站路径 https://www.ideasphere.cn/**：

修改前：

```bash
pathsToMatch: ["https://www.ideasphere.cn/docs/**"],
```

修改后：

```bash
pathsToMatch: ["https://www.ideasphere.cn/**"],
```

修改完成后，进行测试，如果能成功提取到数据则表示没问题，点击右上角的"Save"按钮保存代码：

![image-20240622101009539](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240622101009539.png)

切换回"Overview"，点击右上角的 “Restart crawling” 重新爬取数据即可。

![image-20240621113511933](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240621113511933.png)

然而，爬取后得到的records仍旧为0，那肯定是爬取的代码还有问题。

### 修改代码

在博客上面的文章查看源代码，得到各种标签，然后修改爬虫代码如下：

![image-20240628161244531](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240628161244531.png)

重试，可以看到爬取到了数据。

![image-20240628161405662](https://bucket-linxc.oss-cn-guangzhou.aliyuncs.com/images/image-20240628161405662.png)

保存后重新执行爬取，之后就可以在网站上进行全文搜索了。
